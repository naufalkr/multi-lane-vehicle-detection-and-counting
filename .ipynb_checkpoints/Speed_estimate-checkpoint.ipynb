{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573230a3-5c50-4a16-9f28-51576e248791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\anaconda\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\n",
      "   ---------------------------------------- 0.0/898.7 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/898.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 898.7/898.7 kB 2.1 MB/s eta 0:00:00\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Using cached ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: sympy, opencv-python, torch, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed opencv-python-4.10.0.84 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 ultralytics-8.3.49 ultralytics-thop-2.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bc54c0-1ae2-4e2c-9448-6d0da022c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.3.49'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ef8725-692d-4996-839d-29e9929b2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import*\n",
    "import os\n",
    "import time\n",
    "\n",
    "model=YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475d2e4a-8d33-449f-90da-2d7c7ff11230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d0e920-6d2e-4f11-9f71-a99acce120bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "tracker = Tracker()\n",
    "down = {}\n",
    "up = {}\n",
    "counter_down = []\n",
    "counter_up = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b834252f-730e-40f7-85f6-1273c564724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_line_y = 128\n",
    "red_line_y = 198\n",
    "blue_line_y = 268\n",
    "green_line_y = 368\n",
    "offset = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836b09fb-65d4-4ee7-a26a-9041d5a3bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture('highway.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe0926d-80f4-4f2c-b594-e34e3a94a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save frames\n",
    "if not os.path.exists('detected_frames'):\n",
    "    os.makedirs('detected_frames')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (1020, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee9fe53-af20-4123-b339-91c34c54e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    # if count % 2 != 0:\n",
    "    #     continue\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data\n",
    "    a = a.detach().cpu().numpy()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "    list = []\n",
    "\n",
    "    for index, row in px.iterrows():\n",
    "        x1 = int(row[0])\n",
    "        y1 = int(row[1])\n",
    "        x2 = int(row[2])\n",
    "        y2 = int(row[3])\n",
    "        d = int(row[5])\n",
    "        c = class_list[d]\n",
    "        if 'car' in c:\n",
    "            list.append([x1, y1, x2, y2])\n",
    "    bbox_id = tracker.update(list)\n",
    "\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, id = bbox\n",
    "        cx = int(x3 + x4) // 2\n",
    "        cy = int(y3 + y4) // 2\n",
    "\n",
    "        # if red_line_y<(cy+offset) and red_line_y > (cy-offset):\n",
    "        #    down[id]=time.time()   # current time when vehichle touch the first line\n",
    "        # if id in down:\n",
    "          \n",
    "        #    if blue_line_y<(cy+offset) and blue_line_y > (cy-offset):\n",
    "        #      elapsed_time=time.time() - down[id]  # current time when vehicle touch the second line. Also we a re minusing the previous time ( current time of line 1)\n",
    "        #      if counter_down.count(id)==0:\n",
    "        #         counter_down.append(id)\n",
    "        #         distance = 10 # meters - distance between the 2 lines is 10 meters\n",
    "        #         a_speed_ms = distance / elapsed_time\n",
    "        #         a_speed_kh = a_speed_ms * 3.6  # this will give kilometers per hour for each vehicle. This is the condition for going downside\n",
    "        #         cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "        #         cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)  # Draw bounding box\n",
    "        #         cv2.putText(frame,str(id),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,0.6,(255,255,255),1)\n",
    "        #         cv2.putText(frame,str(int(a_speed_kh))+'Km/h',(x4,y4 ),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "\n",
    "                \n",
    "        # #####going UP#####     \n",
    "        # if blue_line_y<(cy+offset) and blue_line_y > (cy-offset):\n",
    "        #    up[id]=time.time()\n",
    "        # if id in up:\n",
    "\n",
    "        #    if red_line_y<(cy+offset) and red_line_y > (cy-offset):\n",
    "        #      elapsed1_time=time.time() - up[id]\n",
    "        #      # formula of speed= distance/time  (distance travelled and elapsed time) Elapsed time is It represents the duration between the starting point and the ending point of the movement.\n",
    "        #      if counter_up.count(id)==0:\n",
    "        #         counter_up.append(id)      \n",
    "        #         distance1 = 10 # meters  (Distance between the 2 lines is 10 meters )\n",
    "        #         a_speed_ms1 = distance1 / elapsed1_time\n",
    "        #         a_speed_kh1 = a_speed_ms1 * 3.6\n",
    "        #         cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "        #         cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)  # Draw bounding box\n",
    "        #         cv2.putText(frame,str(id),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,0.6,(255,255,255),1)\n",
    "        #         cv2.putText(frame,str(int(a_speed_kh1))+'Km/h',(x4,y4),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "\n",
    "        if red_line_y < (cy + offset) and red_line_y > (cy - offset):\n",
    "            down[id] = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Waktu dalam detik dari video\n",
    "        if id in down:\n",
    "            if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):\n",
    "                elapsed_time = (cap.get(cv2.CAP_PROP_POS_MSEC) / 1000) - down[id]\n",
    "                if counter_down.count(id) == 0:\n",
    "                    counter_down.append(id)\n",
    "                    distance = 10  # meters - jarak antar garis\n",
    "                    a_speed_ms = distance / elapsed_time\n",
    "                    a_speed_kh = a_speed_ms * 3.6\n",
    "                    cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "                    cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)  # Kotak deteksi\n",
    "                    cv2.putText(frame, str(id), (x3, y3), cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                    cv2.putText(frame, str(int(a_speed_kh)) + 'Km/h', (x4, y4), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "        \n",
    "        if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):\n",
    "            up[id] = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Waktu dalam detik dari video\n",
    "        if id in up:\n",
    "            if red_line_y < (cy + offset) and red_line_y > (cy - offset):\n",
    "                elapsed1_time = (cap.get(cv2.CAP_PROP_POS_MSEC) / 1000) - up[id]\n",
    "                if counter_up.count(id) == 0:\n",
    "                    counter_up.append(id)\n",
    "                    distance1 = 10  # meters\n",
    "                    a_speed_ms1 = distance1 / elapsed1_time\n",
    "                    a_speed_kh1 = a_speed_ms1 * 3.6\n",
    "                    cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "                    cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)  # Kotak deteksi\n",
    "                    cv2.putText(frame, str(id), (x3, y3), cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                    cv2.putText(frame, str(int(a_speed_kh1)) + 'Km/h', (x4, y4), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "    \n",
    "    text_color = (0, 0, 0)  # Black color for text\n",
    "    yellow_color = (0, 255, 255)  # Yellow color for background\n",
    "    red_color = (0, 0, 255)  # Red color for lines\n",
    "    blue_color = (255, 0, 0)  # Blue color for lines\n",
    "\n",
    "    cv2.rectangle(frame, (0, 0), (250, 90), yellow_color, -1)\n",
    "\n",
    "    cv2.line(frame, (172, 198), (774, 198), red_color, 2)\n",
    "    cv2.putText(frame, ('Red Line'), (172, 198), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (172, 198), (774, 198), red_color, 2)\n",
    "    cv2.putText(frame, ('Red Line'), (172, 198), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.line(frame, (8, 268), (927, 268), blue_color, 2)\n",
    "    cv2.putText(frame, ('Blue Line'), (8, 268), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.putText(frame, ('Going Down - ' + str(len(counter_down))), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame, ('Going Up - ' + str(len(counter_up))), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    # # Save frame\n",
    "    # frame_filename = f'detected_frames/frame_{count}.jpg'\n",
    "    # cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "    # out.write(frame)\n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "    #if cv2.waitKey(0) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f256dfa-cbe7-483b-aaa9-b152cc0d50db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 8 cars, 2 trucks, 122.0ms\n",
      "Speed: 2.1ms preprocess, 122.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 2 trucks, 84.4ms\n",
      "Speed: 3.0ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 92.4ms\n",
      "Speed: 2.3ms preprocess, 92.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 90.3ms\n",
      "Speed: 0.5ms preprocess, 90.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 89.3ms\n",
      "Speed: 0.0ms preprocess, 89.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 89.9ms\n",
      "Speed: 0.0ms preprocess, 89.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 85.1ms\n",
      "Speed: 0.0ms preprocess, 85.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 85.0ms\n",
      "Speed: 4.9ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 87.7ms\n",
      "Speed: 0.0ms preprocess, 87.7ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 75.6ms\n",
      "Speed: 8.0ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 94.7ms\n",
      "Speed: 0.0ms preprocess, 94.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 75.1ms\n",
      "Speed: 5.1ms preprocess, 75.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 79.6ms\n",
      "Speed: 0.0ms preprocess, 79.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 78.1ms\n",
      "Speed: 3.4ms preprocess, 78.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 81.2ms\n",
      "Speed: 2.0ms preprocess, 81.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 80.1ms\n",
      "Speed: 8.1ms preprocess, 80.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 69.9ms\n",
      "Speed: 10.1ms preprocess, 69.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 79.3ms\n",
      "Speed: 0.0ms preprocess, 79.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 75.8ms\n",
      "Speed: 0.0ms preprocess, 75.8ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 80.2ms\n",
      "Speed: 5.6ms preprocess, 80.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 76.8ms\n",
      "Speed: 1.0ms preprocess, 76.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 75.9ms\n",
      "Speed: 0.0ms preprocess, 75.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 1 bench, 80.5ms\n",
      "Speed: 0.0ms preprocess, 80.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 1 bench, 80.2ms\n",
      "Speed: 0.0ms preprocess, 80.2ms inference, 8.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 1 bench, 80.6ms\n",
      "Speed: 5.0ms preprocess, 80.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 1 bench, 85.3ms\n",
      "Speed: 0.0ms preprocess, 85.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 1 bench, 83.1ms\n",
      "Speed: 0.8ms preprocess, 83.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 79.8ms\n",
      "Speed: 4.0ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 64.2ms\n",
      "Speed: 0.0ms preprocess, 64.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 74.8ms\n",
      "Speed: 1.1ms preprocess, 74.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m a_speed_kh1 \u001b[38;5;241m=\u001b[39m a_speed_ms1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3.6\u001b[39m\n\u001b[0;32m     89\u001b[0m cv2\u001b[38;5;241m.\u001b[39mcircle(frame, (cx, cy), \u001b[38;5;241m4\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x3, y3), (x4, y4), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     91\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m), (x3, y3), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[38;5;241m0.6\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     92\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(a_speed_kh1)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKm/h\u001b[39m\u001b[38;5;124m'\u001b[39m, (x4, y4), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[38;5;241m0.8\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import time\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from tracker import Tracker\n",
    "\n",
    "# count = 0\n",
    "# tracker = Tracker()\n",
    "# down = {}\n",
    "# up = {}\n",
    "# counter_down = []\n",
    "# counter_up = []\n",
    "\n",
    "# cap = cv2.VideoCapture('highway.mp4')\n",
    "\n",
    "# # Set line positions\n",
    "# red_line_y = 198\n",
    "# blue_line_y = 268\n",
    "# offset = 6\n",
    "\n",
    "# # Create folder to save frames\n",
    "# if not os.path.exists('detected_frames'):\n",
    "#     os.makedirs('detected_frames')\n",
    "\n",
    "# # Initialize video writer\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter('output.avi', fourcc, 20.0, (1020, 500))\n",
    "\n",
    "# # Process video frames\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     count += 1\n",
    "#     frame = cv2.resize(frame, (1020, 500))  # Resize to reduce frame size\n",
    "    \n",
    "#     # Process every other frame\n",
    "#     if count % 2 != 0:\n",
    "#         continue\n",
    "\n",
    "#     # Predict with model (adjust the model call if needed)\n",
    "#     results = model.predict(frame)\n",
    "#     a = results[0].boxes.data\n",
    "#     a = a.detach().cpu().numpy()\n",
    "#     px = pd.DataFrame(a).astype(\"float\")\n",
    "#     detected_objects = []\n",
    "\n",
    "#     # Filter detected cars\n",
    "#     for index, row in px.iterrows():\n",
    "#         x1, y1, x2, y2, _, c = row[0], row[1], row[2], row[3], row[5], class_list[int(row[5])]\n",
    "#         if 'car' in c:\n",
    "#             detected_objects.append([x1, y1, x2, y2])\n",
    "    \n",
    "#     # Update tracker\n",
    "#     bbox_id = tracker.update(detected_objects)\n",
    "\n",
    "#     for bbox in bbox_id:\n",
    "#         x3, y3, x4, y4, id = bbox\n",
    "#         cx = int(x3 + x4) // 2\n",
    "#         cy = int(y3 + y4) // 2\n",
    "\n",
    "#         # Check crossing red line (going down)\n",
    "#         if red_line_y < (cy + offset) and red_line_y > (cy - offset):\n",
    "#             down[id] = time.time()\n",
    "#         if id in down:\n",
    "#             if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):\n",
    "#                 elapsed_time = time.time() - down[id]\n",
    "#                 if id not in counter_down:\n",
    "#                     counter_down.append(id)\n",
    "#                     distance = 10  # meters\n",
    "#                     a_speed_ms = distance / elapsed_time\n",
    "#                     a_speed_kh = a_speed_ms * 3.6\n",
    "#                     cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "#                     cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)\n",
    "#                     cv2.putText(frame, str(id), (x3, y3), cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 255, 255), 1)\n",
    "#                     cv2.putText(frame, str(int(a_speed_kh)) + 'Km/h', (x4, y4), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "#         # Check crossing blue line (going up)\n",
    "#         if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):\n",
    "#             up[id] = time.time()\n",
    "#         if id in up:\n",
    "#             if red_line_y < (cy + offset) and red_line_y > (cy - offset):\n",
    "#                 elapsed1_time = time.time() - up[id]\n",
    "#                 if id not in counter_up:\n",
    "#                     counter_up.append(id)\n",
    "#                     distance1 = 10  # meters\n",
    "#                     a_speed_ms1 = distance1 / elapsed1_time\n",
    "#                     a_speed_kh1 = a_speed_ms1 * 3.6\n",
    "#                     cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "#                     cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)\n",
    "#                     cv2.putText(frame, str(id), (x3, y3), cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 255, 255), 1)\n",
    "#                     cv2.putText(frame, str(int(a_speed_kh1)) + 'Km/h', (x4, y4), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "#     # Draw lines and info\n",
    "#     cv2.line(frame, (172, red_line_y), (774, red_line_y), (0, 0, 255), 2)  # Red line\n",
    "#     cv2.putText(frame, 'Red Line', (172, red_line_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "#     cv2.line(frame, (8, blue_line_y), (927, blue_line_y), (255, 0, 0), 2)  # Blue line\n",
    "#     cv2.putText(frame, 'Blue Line', (8, blue_line_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.putText(frame, f'Going Down - {len(counter_down)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "#     cv2.putText(frame, f'Going Up - {len(counter_up)}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "#     # Save frame (optional)\n",
    "#     # cv2.imwrite(f'detected_frames/frame_{count}.jpg', frame)\n",
    "#     # out.write(frame)\n",
    "\n",
    "#     cv2.imshow(\"Frames\", frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef7a71-3d03-4d4c-9ee8-91ef339b11e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
